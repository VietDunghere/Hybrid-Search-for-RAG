"""
Module xá»­ lÃ½ dá»¯ liá»‡u: Ä‘á»c vÃ  tiá»n xá»­ lÃ½ cÃ¡c file vÄƒn báº£n phÃ¡p luáº­t
"""
import os
import re
import glob
from typing import List, Dict


def clean_text(text: str) -> str:
    """
    Tiá»n xá»­ lÃ½ vÄƒn báº£n:
    - Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
    - Chuáº©n hÃ³a xuá»‘ng dÃ²ng
    - Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t khÃ´ng cáº§n thiáº¿t
    """
    # Thay tháº¿ nhiá»u dáº¥u xuá»‘ng dÃ²ng liÃªn tiáº¿p báº±ng 2 dáº¥u xuá»‘ng dÃ²ng
    text = re.sub(r'\n\s*\n', '\n\n', text)
    # Loáº¡i bá» khoáº£ng tráº¯ng Ä‘áº§u/cuá»‘i má»—i dÃ²ng
    lines = [line.strip() for line in text.split('\n')]
    text = '\n'.join(lines)
    # Loáº¡i bá» cÃ¡c dÃ²ng chá»‰ chá»©a dáº¥u *
    text = re.sub(r'\n\*+\n', '\n', text)
    text = re.sub(r'^\*+$', '', text, flags=re.MULTILINE)
    # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
    text = re.sub(r'[ \t]+', ' ', text)
    # Loáº¡i bá» dÃ²ng trá»‘ng thá»«a
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()


def extract_doc_metadata(filename: str, content: str) -> Dict:
    """
    TrÃ­ch xuáº¥t metadata tá»« tÃªn file vÃ  ná»™i dung vÄƒn báº£n
    """
    # Láº¥y sá»‘ hiá»‡u tá»« tÃªn file (vÃ­ dá»¥: 01_1999_TT-BXD -> 01/1999/TT-BXD)
    base_name = os.path.splitext(filename)[0]
    # Loáº¡i bá» háº­u tá»‘ _1, _2... náº¿u cÃ³
    base_name_clean = re.sub(r'_(\d+)$', '', base_name)
    doc_number = base_name_clean.replace('_', '/')

    # TrÃ­ch xuáº¥t cÆ¡ quan ban hÃ nh (náº±m á»Ÿ Ä‘áº§u file)
    issuing_body = ""
    for line in content.split('\n')[:10]:
        line = line.strip()
        if line and line != "********" and "Cá»˜NG" not in line and "Äá»™c láº­p" not in line:
            issuing_body = line
            break

    return {
        "filename": filename,
        "doc_number": doc_number,
        "issuing_body": issuing_body,
        "source": filename,
    }


def load_documents(data_dir: str) -> List[Dict]:
    """
    Äá»c táº¥t cáº£ cÃ¡c file .txt trong thÆ° má»¥c dá»¯ liá»‡u
    
    Returns:
        List[Dict]: Danh sÃ¡ch cÃ¡c document, má»—i document chá»©a:
            - content: ná»™i dung vÄƒn báº£n Ä‘Ã£ Ä‘Æ°á»£c tiá»n xá»­ lÃ½
            - metadata: thÃ´ng tin metadata
    """
    documents = []
    txt_files = sorted(glob.glob(os.path.join(data_dir, "*.txt")))
    
    if not txt_files:
        print(f"[WARNING] KhÃ´ng tÃ¬m tháº¥y file .txt nÃ o trong {data_dir}")
        return documents

    for filepath in txt_files:
        filename = os.path.basename(filepath)
        print(f"  ğŸ“„ Äang Ä‘á»c: {filename}")
        
        try:
            # Thá»­ Ä‘á»c vá»›i UTF-8
            with open(filepath, 'r', encoding='utf-8') as f:
                raw_content = f.read()
        except UnicodeDecodeError:
            # Fallback sang UTF-8 with BOM hoáº·c latin-1
            try:
                with open(filepath, 'r', encoding='utf-8-sig') as f:
                    raw_content = f.read()
            except UnicodeDecodeError:
                with open(filepath, 'r', encoding='latin-1') as f:
                    raw_content = f.read()
        
        # Tiá»n xá»­ lÃ½ vÄƒn báº£n
        cleaned_content = clean_text(raw_content)
        
        # TrÃ­ch xuáº¥t metadata
        metadata = extract_doc_metadata(filename, cleaned_content)
        
        documents.append({
            "content": cleaned_content,
            "metadata": metadata
        })
        
    print(f"\nâœ… ÄÃ£ Ä‘á»c {len(documents)} vÄƒn báº£n tá»« thÆ° má»¥c {data_dir}")
    return documents


if __name__ == "__main__":
    from config import DATA_DIR
    docs = load_documents(DATA_DIR)
    for doc in docs:
        print(f"\n--- {doc['metadata']['filename']} ---")
        print(f"  Sá»‘ hiá»‡u: {doc['metadata']['doc_number']}")
        print(f"  CÆ¡ quan: {doc['metadata']['issuing_body']}")
        print(f"  Äá»™ dÃ i: {len(doc['content'])} kÃ½ tá»±")
        print(f"  Preview: {doc['content'][:200]}...")
