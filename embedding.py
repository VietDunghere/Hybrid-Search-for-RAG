"""
Module embedding: t·∫°o vector embeddings cho c√°c chunks s·ª≠ d·ª•ng sentence-transformers
v√† l∆∞u tr·ªØ trong ChromaDB
"""
import os
from typing import List, Dict, Optional

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer

from config import EMBEDDING_MODEL, EMBEDDING_DEVICE, CHROMA_DIR, COLLECTION_NAME


class EmbeddingManager:
    """Qu·∫£n l√Ω vi·ªác t·∫°o embeddings v√† l∆∞u tr·ªØ trong ChromaDB"""
    
    def __init__(
        self,
        model_name: str = EMBEDDING_MODEL,
        device: str = EMBEDDING_DEVICE,
        chroma_dir: str = CHROMA_DIR,
        collection_name: str = COLLECTION_NAME,
    ):
        print(f"üîÑ ƒêang t·∫£i m√¥ h√¨nh embedding: {model_name}...")
        self.model = SentenceTransformer(model_name, device=device)
        print(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh embedding th√†nh c√¥ng (device={device})")
        
        # Kh·ªüi t·∫°o ChromaDB
        self.chroma_client = chromadb.PersistentClient(path=chroma_dir)
        self.collection_name = collection_name
        self.collection = None
    
    def encode(self, texts: List[str], batch_size: int = 32, show_progress: bool = True) -> List[List[float]]:
        """
        T·∫°o embeddings cho danh s√°ch texts
        """
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=show_progress,
            normalize_embeddings=True  # Normalize cho cosine similarity
        )
        return embeddings.tolist()
    
    def encode_query(self, query: str) -> List[float]:
        """T·∫°o embedding cho m·ªôt query ƒë∆°n"""
        embedding = self.model.encode(
            [query],
            normalize_embeddings=True
        )
        return embedding[0].tolist()
    
    def create_collection(self, force_recreate: bool = False):
        """
        T·∫°o ho·∫∑c l·∫•y collection trong ChromaDB
        """
        if force_recreate:
            try:
                self.chroma_client.delete_collection(self.collection_name)
                print(f"üóëÔ∏è ƒê√£ x√≥a collection c≈©: {self.collection_name}")
            except Exception:
                pass
        
        self.collection = self.chroma_client.get_or_create_collection(
            name=self.collection_name,
            metadata={"hnsw:space": "cosine"}  # S·ª≠ d·ª•ng cosine similarity
        )
        print(f"‚úÖ Collection '{self.collection_name}' ƒë√£ s·∫µn s√†ng (count={self.collection.count()})")
        return self.collection
    
    def index_chunks(self, chunks: List[Dict], force_recreate: bool = False):
        """
        T·∫°o embeddings v√† index t·∫•t c·∫£ chunks v√†o ChromaDB
        
        Args:
            chunks: Danh s√°ch chunks t·ª´ module chunking
            force_recreate: N·∫øu True, x√≥a collection c≈© v√† t·∫°o l·∫°i
        """
        self.create_collection(force_recreate=force_recreate)
        
        # N·∫øu ƒë√£ c√≥ d·ªØ li·ªáu v√† kh√¥ng force_recreate
        if self.collection.count() > 0 and not force_recreate:
            print(f"‚ÑπÔ∏è Collection ƒë√£ c√≥ {self.collection.count()} chunks, b·ªè qua indexing.")
            return
        
        print(f"\nüîÑ ƒêang t·∫°o embeddings cho {len(chunks)} chunks...")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu
        ids = [chunk["chunk_id"] for chunk in chunks]
        documents = [chunk["content"] for chunk in chunks]
        metadatas = [chunk["metadata"] for chunk in chunks]
        
        # T·∫°o embeddings
        embeddings = self.encode(documents)
        
        # Index v√†o ChromaDB theo batch (ChromaDB gi·ªõi h·∫°n ~41666 items/batch)
        batch_size = 500
        for i in range(0, len(ids), batch_size):
            end = min(i + batch_size, len(ids))
            self.collection.add(
                ids=ids[i:end],
                documents=documents[i:end],
                embeddings=embeddings[i:end],
                metadatas=metadatas[i:end]
            )
            print(f"  Indexed batch {i//batch_size + 1}: chunks {i}-{end-1}")
        
        print(f"‚úÖ ƒê√£ index {len(chunks)} chunks v√†o ChromaDB")
    
    def dense_search(self, query: str, top_k: int = 5) -> List[Dict]:
        """
        T√¨m ki·∫øm dense (vector similarity) trong ChromaDB
        
        Returns:
            List[Dict]: K·∫øt qu·∫£ v·ªõi score, content, metadata
        """
        if self.collection is None:
            self.create_collection()
        
        query_embedding = self.encode_query(query)
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )
        
        search_results = []
        for i in range(len(results["ids"][0])):
            search_results.append({
                "chunk_id": results["ids"][0][i],
                "content": results["documents"][0][i],
                "metadata": results["metadatas"][0][i],
                "distance": results["distances"][0][i],
                "dense_score": 1 - results["distances"][0][i],  # Convert distance to similarity
            })
        
        return search_results


if __name__ == "__main__":
    from config import DATA_DIR, CHUNK_SIZE, CHUNK_OVERLAP
    from data_processing import load_documents
    from chunking import chunk_documents
    
    # 1. Load documents
    docs = load_documents(DATA_DIR)
    
    # 2. Chunk documents
    chunks = chunk_documents(docs, CHUNK_SIZE, CHUNK_OVERLAP)
    
    # 3. Create embeddings and index
    emb_manager = EmbeddingManager()
    emb_manager.index_chunks(chunks, force_recreate=True)
    
    # 4. Test dense search
    query = "Thu·∫ø gi√° tr·ªã gia tƒÉng ƒë·∫ßu ra trong d·ª± to√°n x√¢y l·∫Øp"
    results = emb_manager.dense_search(query, top_k=3)
    
    print(f"\nüîç Dense search results for: '{query}'")
    for r in results:
        print(f"\n  [{r['chunk_id']}] score={r['dense_score']:.4f}")
        print(f"  Source: {r['metadata']['filename']}")
        print(f"  Content: {r['content'][:200]}...")
